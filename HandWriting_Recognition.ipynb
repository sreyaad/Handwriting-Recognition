{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Offline Handwriting Recognition using CNN\n\nThis notebook is the implementation of deep learning models for classify writers based on their writing styles. Dataset used is IAM Handwriting Dataset. Summary of this notebook is also presented on the project [website](https://tejasreddy9.github.io/handwriting_cnn). I've only considered only 50 writers data as that was sufficient in the classification. More might cause overfitting. Each writer is given a set of sentences. Each sentence is taken seperately and prerocessed. \n\n## Classification Model\n\nI've built this using Keras in Python with TensorFlow as backend. This model is language independent as we dont consider the letters or words in particular, but patches of image size 113x113 are extracted and fit into the model for learning. \n\n## Results\n\nThis model given impressive 94% accuracy on test data.\n\n## Dataset\n[IAM Handwritten Dataset](https://www.kaggle.com/tejasreddy/iam-handwriting-top50)\n\nI've uploaded this dataset to kaggle. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### Imports\nImport these packages to the project."},{"metadata":{"trusted":true,"_uuid":"ff03e0be8b022e42a9f1c880c36bf45c21f04402"},"cell_type":"code","source":"from __future__ import division\nimport numpy as np\nimport os\nimport glob\n\nfrom random import *\nfrom PIL import Image\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\nfrom keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD, Adam, RMSprop","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c92d898a98684fe82c0ffb1294f9c93744899c7"},"cell_type":"markdown","source":"These are the forms in the dataset for quick access from manipulation of the file names on each column. Let's create a dictionary with form and writer mapping."},{"metadata":{"trusted":true,"_uuid":"4916eca832ed28a895eca80142ad6c419956a397"},"cell_type":"code","source":"d = {}\nfrom subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# forms = pd.read_csv('../input/iam-handwriting-top50/forms_for_parsing.txt', header=None)\n# print(forms.head)\nwith open('../input/forms_for_parsing.txt') as f:\n    for line in f:\n        key = line.split(' ')[0]\n        writer = line.split(' ')[1]\n        d[key] = writer\nprint(len(d.keys()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b53f31b2cba8e74f0870005093e191daf3fa54c5"},"cell_type":"markdown","source":"All file-names list and target-writer names list are created."},{"metadata":{"trusted":true,"_uuid":"43eb1b4e0c76027ca35a89c7f86e5cdfd65dca69"},"cell_type":"code","source":"tmp = []\ntarget_list = []\n\npath_to_files = os.path.join('../input/data_subset/data_subset', '*')\nfor filename in sorted(glob.glob(path_to_files)):\n#     print(filename)\n    tmp.append(filename)\n    image_name = filename.split('/')[-1]\n    file, ext = os.path.splitext(image_name)\n    parts = file.split('-')\n    form = parts[0] + '-' + parts[1]\n    for key in d:\n        if key == form:\n            target_list.append(str(d[form]))\n\nimg_files = np.asarray(tmp)\nimg_targets = np.asarray(target_list)\nprint(img_files.shape)\nprint(img_targets.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b80001a82c05277cbf74b0a92f0dd87f7926cab1"},"cell_type":"markdown","source":"### Visualization of images\nLet's visualize the image data."},{"metadata":{"trusted":true,"_uuid":"3485223d40941ab326c76d364bc1136a566e7749"},"cell_type":"code","source":"for filename in img_files[:3]:\n    img=mpimg.imread(filename)\n    plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap ='gray')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b371aecb3ff7e314201fd45ed31136c942a4d52c"},"cell_type":"markdown","source":"Good to observe that there are no categorical data. So, normalisation is done using label encoder."},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"efb470a284b84af0b541780aa953396382b9b9a7"},"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(img_targets)\nencoded_Y = encoder.transform(img_targets)\n\nprint(img_files[:5], img_targets[:5], encoded_Y[:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4c0e0f902db4f78da7b89505059b74e3ed75887"},"cell_type":"markdown","source":"Splitting of data into training and validation sets for cross validation with 4:1:1 ratio."},{"metadata":{"trusted":true,"_uuid":"cd0cad3ba7235ad7392c9ef22240bf32d33d4d43"},"cell_type":"code","source":"train_files, rem_files, train_targets, rem_targets = train_test_split(\n        img_files, encoded_Y, train_size=0.66, random_state=52, shuffle= True)\n\nvalidation_files, test_files, validation_targets, test_targets = train_test_split(\n        rem_files, rem_targets, train_size=0.5, random_state=22, shuffle=True)\n\nprint(train_files.shape, validation_files.shape, test_files.shape)\nprint(train_targets.shape, validation_targets.shape, test_targets.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4129fb056d957a234bb1d548e37624bb104c6bd3"},"cell_type":"markdown","source":"### Input to the model\n\nAs said before, we take patches of data, each of size 113x133. A generator function is implemented for that purpose."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ac174996e85c0cc34466494c032d4ccd66768c69"},"cell_type":"code","source":"# Generator function for generating random crops from each sentence\n\n# # Now create generators for randomly cropping 113x113 patches from these images\n\nbatch_size = 16\nnum_classes = 50\n\n# Start with train generator shared in the class and add image augmentations\ndef generate_data(samples, target_files,  batch_size=batch_size, factor = 0.1 ):\n    num_samples = len(samples)\n    from sklearn.utils import shuffle\n    while 1: # Loop forever so the generator never terminates\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = samples[offset:offset+batch_size]\n            batch_targets = target_files[offset:offset+batch_size]\n\n            images = []\n            targets = []\n            for i in range(len(batch_samples)):\n                batch_sample = batch_samples[i]\n                batch_target = batch_targets[i]\n                im = Image.open(batch_sample)\n                cur_width = im.size[0]\n                cur_height = im.size[1]\n\n                # print(cur_width, cur_height)\n                height_fac = 113 / cur_height\n\n                new_width = int(cur_width * height_fac)\n                size = new_width, 113\n\n                imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n                now_width = imresize.size[0]\n                now_height = imresize.size[1]\n                # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n\n                avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n\n                # Pick random x%\n                pick_num = int(len(avail_x_points)*factor)\n\n                # Now pick\n                random_startx = sample(avail_x_points,  pick_num)\n\n                for start in random_startx:\n                    imcrop = imresize.crop((start, 0, start+113, 113))\n                    images.append(np.asarray(imcrop))\n                    targets.append(batch_target)\n\n            # trim image to only see section with road\n            X_train = np.array(images)\n            y_train = np.array(targets)\n\n            #reshape X_train for feeding in later\n            X_train = X_train.reshape(X_train.shape[0], 113, 113, 1)\n            #convert to float and normalize\n            X_train = X_train.astype('float32')\n            X_train /= 255\n\n            #One hot encode y\n            y_train = to_categorical(y_train, num_classes)\n            yield shuffle(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d5c49f71f30de1bf86253d44afe5cef879ed1c3"},"cell_type":"markdown","source":"For training and testing,  generator function is called with the intent of making train and test generator data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5e1b1e517cb2db59aaf6ecabdc62b553057b9bdd"},"cell_type":"code","source":"train_generator = generate_data(train_files, train_targets, batch_size=batch_size, factor = 0.3)\nvalidation_generator = generate_data(validation_files, validation_targets, batch_size=batch_size, factor = 0.3)\ntest_generator = generate_data(test_files, test_targets, batch_size=batch_size, factor = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95ff8485f8b8c9ecaacd4fdf1d618dac98be0e1c"},"cell_type":"markdown","source":"A Keras Model is built. Summary of the model is printed below."},{"metadata":{"trusted":true,"_uuid":"0eadd72c9a88c06049746d9e8bd1b82931eafa82"},"cell_type":"code","source":"def resize_image(image):\n    import tensorflow as tf\n    return tf.image.resize_images(image,[56,56])\n\n# Function to resize image to 64x64\nrow, col, ch = 113, 113, 1\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))\n\n# Resise data within the neural network\nmodel.add(Lambda(resize_image))  #resize images to allow for easy computation\n\n# CNN model - Building the model suggested in paper\n\nmodel.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n\nmodel.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n\nmodel.add(Convolution2D(filters= 128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool3'))\n\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(512, name='dense1'))  #1024\n# model.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, name='dense2'))  #1024\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_classes,name='output'))\nmodel.add(Activation('softmax'))  #softmax since output is within 50 classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7a4f8de3dd87584c52e407c774f22d731bd00de"},"cell_type":"markdown","source":"### Training the model\n\nLet's take 8 epochs. And the following specifications."},{"metadata":{"trusted":true,"_uuid":"be9bb7360d3cfc14cdc2a5df5ad47defd05776e3","collapsed":true},"cell_type":"code","source":"# nb_epoch = 8\n\n# samples_per_epoch = 3268\n# nb_val_samples = 842\n\n\n# #save every model using Keras checkpoint\n# from keras.callbacks import ModelCheckpoint\n# filepath=\"checkpoint2/check-{epoch:02d}-{val_loss:.4f}.hdf5\"\n# checkpoint = ModelCheckpoint(filepath= filepath, verbose=1, save_best_only=False)\n# callbacks_list = [checkpoint]\n\n# #Model fit generator\n# history_object = model.fit_generator(train_generator, samples_per_epoch= samples_per_epoch,\n#                                      validation_data=validation_generator,\n#                                      nb_val_samples=nb_val_samples, nb_epoch=nb_epoch, verbose=1, callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be385264509ecce0061864f0f30f0c95e49e4474"},"cell_type":"markdown","source":"### Performance Metrics\n\nLet's now test our model for calculating accuracy."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"921e6244c1ebeb7ccac680503c0987936a42aace"},"cell_type":"code","source":"# model.load_weights('low_loss.hdf5')\n# scores = model.evaluate_generator(test_generator,842) \n# print(\"Accuracy = \", scores[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b599a7eca29767294208f579b757fcbe12ded7d"},"cell_type":"markdown","source":"Load in test data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"56f8b903170d0f4d7d496ace5f2954141d5a7e81"},"cell_type":"code","source":"# images = []\n# for filename in test_files[:50]:\n#     im = Image.open(filename)\n#     cur_width = im.size[0]\n#     cur_height = im.size[1]\n\n#     # print(cur_width, cur_height)\n#     height_fac = 113 / cur_height\n\n#     new_width = int(cur_width * height_fac)\n#     size = new_width, 113\n\n#     imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n#     now_width = imresize.size[0]\n#     now_height = imresize.size[1]\n#     # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n\n#     avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n\n#     # Pick random x%\n#     factor = 0.1\n#     pick_num = int(len(avail_x_points)*factor)\n    \n#     random_startx = sample(avail_x_points,  pick_num)\n\n#     for start in random_startx:\n#         imcrop = imresize.crop((start, 0, start+113, 113))\n#         images.append(np.asarray(imcrop))\n        \n#     X_test = np.array(images)\n    \n#     X_test = X_test.reshape(X_test.shape[0], 113, 113, 1)\n#     #convert to float and normalize\n#     X_test = X_test.astype('float32')\n#     X_test /= 255\n#     shuffle(X_test)\n\n# print(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c69d84dcc9a5a5df52f441d444bf3d64cbeb3ac5"},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0458779a20d43667eb416904ddff447b49282124"},"cell_type":"code","source":"# predictions = model.predict(X_test, verbose =1)\n\n# print(predictions.shape)\n# predicted_writer = []\n# for pred in predictions:\n#     predicted_writer.append(np.argmax(pred))\n# print(len(predicted_writer))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12f114167ec93e64f4ef3901b544df40ca8aeb67"},"cell_type":"markdown","source":"### Insights"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5da1e6b4bc0c262002a99f590c8f993dcd3780ea"},"cell_type":"code","source":"# writer_number = 18\n# total_images =10\n# counter = 0\n# for i in range(len(predicted_writer)//10):\n#     if predicted_writer[i] == writer_number:\n#         image = X_test[i].squeeze()\n#         plt.figure(figsize=(2,2))\n#         plt.imshow(image, cmap ='gray')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}